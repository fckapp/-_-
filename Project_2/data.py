import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
import torch
from torchvision import transforms

# í˜ì´ì§€
st.set_page_config(
    page_title="ë¶ˆëŸ‰í’ˆ ì˜ˆì¸¡ í”„ë¡œê·¸ë¨",
    page_icon="ğŸ“ˆ"
)

# 1. ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜


class MyModel(torch.nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()
        self.fc = torch.nn.Linear(10, 2)  # ì…ë ¥ ì°¨ì› 10, ì¶œë ¥ ì°¨ì› 2

    def forward(self, x):
        return self.fc(x)


# 2. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
model = MyModel()

# 3. ëª¨ë¸ ë¡œë“œ (CPUì—ì„œ ë¡œë“œ)
# torch.load('last100.pt')
############ chat gpt
# ê°€ì¤‘ì¹˜ íŒŒì¼ ë¡œë“œ
checkpoint = torch.load('last100.pt', map_location=torch.device('cpu'))

# ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ
model.load_state_dict(checkpoint['model'], strict=False)  # strict=Falseë¡œ í‚¤ ì¼ì¹˜ ì—¬ë¶€ ë¬´ì‹œ

# 4. í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (ì˜ˆ: dropoutì´ë‚˜ batch normalizationì„ ì‚¬ìš©í•  ê²½ìš°)
model.eval()

# 4. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜


def preprocess_image(image):
    transform = transforms.Compose([
        transforms.Resize((10, 10)),  # ëª¨ë¸ì˜ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
        transforms.ToTensor()
    ])
    # ì´ë¯¸ì§€ í…ì„œë¥¼ 10ì°¨ì›ìœ¼ë¡œ ë³€í™˜
    image_tensor = transform(image).view(-1)  # 1D í…ì„œë¡œ ë³€í™˜
    return image_tensor[:10].unsqueeze(0)  # ì²« 10ê°œ ê°’ë§Œ ì‚¬ìš©í•˜ê³  ë°°ì¹˜ ì°¨ì› ì¶”ê°€


# 5. Streamlit ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ“ˆ ë¶ˆëŸ‰í’ˆ ì˜ˆì¸¡ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜")

# style ì…íˆê¸°
st.markdown('''
    <style>
            .stMarkdown p{
                font-size: 20px;
            }
            .e1nzilvr3{
                display: flex;
                justify-content: center;
            }
            .e1nzilvr5{
                display: flex;
                justify-content: center;
            }
    </style>
''', unsafe_allow_html=True)

# ì´ë¯¸ì§€ ì—…ë¡œë“œ
results = []  # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
images = []  # ì´ë¯¸ì§€ì™€ íŒŒì¼ ì´ë¦„ ì €ì¥

st.info("ì˜ˆì¸¡í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”")
uploaded_files = st.file_uploader(
    "ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥ í•©ë‹ˆë‹¤.", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

if uploaded_files:
    for uploaded_file in uploaded_files:
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(uploaded_file)
        images.append((image, uploaded_file.name))

# ì˜ˆì¸¡ í™•ì¸ ë²„íŠ¼
if st.button("ì˜ˆì¸¡ í™•ì¸", use_container_width=True, key="predict_button"):
    for img, file_name in images:
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        input_tensor = preprocess_image(img)

        # ëª¨ë¸ì— ì…ë ¥ ë°ì´í„°ë¥¼ í†µê³¼ì‹œì¼œ ì˜ˆì¸¡ ì–»ê¸°
        with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”
            output = model(input_tensor)

        # ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
        prediction = torch.argmax(output, dim=1).item()  # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ì¸ë±ìŠ¤
        result = "ë¶ˆëŸ‰í’ˆ" if prediction == 0 else "ì–‘í’ˆ"
        # st.write(f'ë””ë²„ê¹…>> predictionì€ {prediction}')
        results.append((file_name, result))  # ê²°ê³¼ ì €ì¥

    # st.write(f'ë””ë²„ê¹…>> {results}')
    # ëª¨ë“  ì´ë¯¸ì§€ì™€ ê²°ê³¼ë¥¼ ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
    st.subheader("ëª¨ë“  ì´ë¯¸ì§€ ë° ì˜ˆì¸¡ ê²°ê³¼")
    # ì „ì²´ ì´ë¯¸ì§€ì™€ ê²°ê³¼ í‘œì‹œ
    cols = st.columns(3)
    for i, (img, file_name) in enumerate(images):
        with cols[i % 3]:
            st.image(
                img, caption=f'ì—…ë¡œë“œëœ ì´ë¯¸ì§€: {file_name}', use_column_width=True)
            # st.write(results) # ë””ë²„ê¹…
            st.write(f"ì˜ˆì¸¡ ê²°ê³¼: {results[i][1]}")  # ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
